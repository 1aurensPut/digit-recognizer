---
title: "The Digit Recognizer Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
```

# The project

In collaboration with Optimistic Data Spirit, this is my process in R to solve the Digit Recognizer Project Kaggle competition and hence to learn computer vision fundamentals. For all details about this competition see <https://www.kaggle.com/c/digit-recognizer/data>.

## The data

The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems (Wikipedia). Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. Each pixel has a single pixel-value between 0 and 255 associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker (Kaggle website).

We received three csv files: 

* train.csv - the training dataset with 785 columns. The first column, called "label", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).

* test.csv - same as the training set, except that it does not contain the "label" column.

* sample-submission.csv - for each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict.

## The evaluation

The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images.

# My approach

```{r, include = FALSE}
# clean memory
rm(list=ls())
# call libraries
library(keras)
```

Watching the Deep Learning with R in Motion: the MNIST dataset video from Manning publication, I took the follwing notes: 

This is a single label multi-class (10 options) classification (trying to predict a categorical variable) problem. 
This is a computer vision problem for which we can use a Convolutional Network (CNN).

The three phases of machine learning projects are: 

1. Data preparation
    + Obtain
    + Rearrange
    + Normalize
    + Reformat
2. Model definition
    + I
    + I
3. Evaluation
    + Item 3a
    + Item 3b

Steps to solve this problem include:

* Normalizing the values so that each pixel is represented by a value between 0 and 1 (as opposed to 0 and 255)

## Data preparation

### Obtain data

I obtained my dataset from the Kaggle competition. 

```{r, include = FALSE}
train.data <- data <- read.csv("~/projects/kaggle/digit-recognizer/data/raw/train.csv")
test.data <- read.csv("~/projects/kaggle/digit-recognizer/data/raw/test.csv")
dim(train.data)
dim(test.data)
```

### Rearrange data

Want a 2D tensor (like a data.frame or classical R matrix). This was done by Kaggle for us.

### Normalize the values

Normalizing the values so that each pixel is represented by a value between 0 and 1 (as opposed to 0 and 255)

```{r, include = FALSE}
norm.train.data <- train.data/255
norm.train.data$label <- norm.train.data*255

norm.test.data <- train.data/255
```

So we now have two 2D normalize tensors.

## Useful resources

https://www.youtube.com/watch?v=K6e8WnJeivQ

